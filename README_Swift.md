# Qwen2.5-VL Swift å®Œæ•´å®ç°

åŸºäº mlx-swift çš„ Qwen2.5-VL-3B å¤šæ¨¡æ€æ¨ç† Swift å®Œæ•´å®ç°ï¼Œä¸¥æ ¼æŒ‰ç…§æ¨¡å‹æ¶æ„å®ç°ï¼ŒåŒ…æ‹¬å®Œæ•´çš„ tokenizationã€image encodingã€cross-modal attention ç­‰ç»„ä»¶ï¼Œæ”¯æŒæœ¬åœ°å›¾ç‰‡ç¾å­¦åˆ†æã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸ—ï¸ **å®Œæ•´æ¨¡å‹æ¶æ„**: ä¸¥æ ¼æŒ‰ç…§ Qwen2.5-VL æ¶æ„å®ç°ï¼ŒåŒ…æ‹¬ï¼š
  - Qwen2.5 è¯­è¨€æ¨¡å‹ï¼ˆ36å±‚ Transformerï¼‰
  - Vision Transformerï¼ˆ32å±‚ï¼Œå¸¦å…¨æ³¨æ„åŠ›å—ï¼‰
  - Multi-Head Grouped Query Attention
  - RoPE ä½ç½®ç¼–ç å’Œ RMSNorm
  - SwiGLU æ¿€æ´»å‡½æ•°
- ğŸ”¤ **å®Œæ•´ Tokenizer**: 
  - BPE ç¼–ç /è§£ç 
  - ç‰¹æ®Š tokens å¤„ç†
  - èŠå¤©æ¨¡æ¿æ ¼å¼åŒ–
- ğŸ–¼ï¸ **å¤šæ ¼å¼å›¾ç‰‡æ”¯æŒ**: PNG, JPEG, HEIC, WebP, BMP, TIFF, GIF
- ğŸ§  **è·¨æ¨¡æ€èåˆ**: çœŸæ­£çš„ cross-modal attention æœºåˆ¶
- ğŸ¯ **ç¾å­¦åˆ†æ**: ä¸“é—¨é’ˆå¯¹å›¾ç‰‡ç¾å­¦è´¨é‡çš„åˆ†æåŠŸèƒ½
- ğŸ“± **iOS/macOS å…¼å®¹**: æ”¯æŒåœ¨ iOS å’Œ macOS å¹³å°è¿è¡Œ
- ğŸ”„ **æµå¼è¾“å‡º**: æ”¯æŒå®æ—¶æµå¼æ–‡æœ¬ç”Ÿæˆ
- ğŸ’¾ **å†…å­˜ä¼˜åŒ–**: è‡ªåŠ¨è°ƒæ•´å›¾ç‰‡å°ºå¯¸ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
- âš¡ **æœ¬åœ°æ¨ç†**: åŸºäºæœ¬åœ°éƒ¨ç½²çš„ Qwen æ¨¡å‹ï¼Œæ— éœ€ç½‘ç»œè¿æ¥
- ğŸ”§ **é‡åŒ–æ”¯æŒ**: æ”¯æŒ 4-bit é‡åŒ–æ¨¡å‹æ¨ç†

## é¡¹ç›®ç»“æ„

```
QwenVLSwift/
â”œâ”€â”€ Package.swift                             # Swift åŒ…é…ç½®æ–‡ä»¶
â”œâ”€â”€ Sources/
â”‚   â”œâ”€â”€ QwenVLSwift/
â”‚   â”‚   â”œâ”€â”€ Qwen25VLModel.swift              # å®Œæ•´æ¨¡å‹æ¶æ„å®ç°
â”‚   â”‚   â”œâ”€â”€ Qwen25VLInferencePipeline.swift  # æ¨ç†ç®¡é“
â”‚   â”‚   â””â”€â”€ QwenVLInference.swift            # é«˜çº§ API æ¥å£
â”‚   â””â”€â”€ QwenVLExample/
â”‚       â””â”€â”€ QwenVLExample.swift              # å®Œæ•´ç¤ºä¾‹ç¨‹åº
â”œâ”€â”€ Tests/
â”‚   â””â”€â”€ QwenVLSwiftTests/
â”‚       â””â”€â”€ QwenVLSwiftTests.swift           # å•å…ƒæµ‹è¯•
â””â”€â”€ Models/                                  # æ¨¡å‹æ–‡ä»¶ç›®å½•
    â””â”€â”€ models--mlx-community--Qwen2.5-VL-3B-Instruct-4bit/
        â””â”€â”€ snapshots/46d4cf06a06ffc1a766c214174f9cbed2f45bcab/
            â”œâ”€â”€ config.json                  # æ¨¡å‹é…ç½®
            â”œâ”€â”€ model.safetensors           # æ¨¡å‹æƒé‡
            â”œâ”€â”€ vocab.json                  # è¯æ±‡è¡¨
            â”œâ”€â”€ merges.txt                 # BPE merges
            â””â”€â”€ tokenizer_config.json      # Tokenizer é…ç½®
```

## æ¶æ„è¯´æ˜

### æ ¸å¿ƒç»„ä»¶

1. **Qwen25VLForConditionalGeneration**: ä¸»æ¨¡å‹ç±»ï¼ŒåŒ…å«ï¼š
   - `Qwen25LanguageModel`: è¯­è¨€æ¨¡å‹éƒ¨åˆ†
   - `VisionTransformer`: è§†è§‰ç¼–ç å™¨
   - `visualProjector`: è§†è§‰ç‰¹å¾æŠ•å½±å±‚

2. **Qwen25Tokenizer**: å®Œæ•´çš„ BPE tokenizer å®ç°
   - æ”¯æŒç‰¹æ®Š tokens (vision_start, vision_end, image_pad ç­‰)
   - èŠå¤©æ¨¡æ¿æ ¼å¼åŒ–
   - ç¼–ç /è§£ç åŠŸèƒ½

3. **VisionTransformer**: è§†è§‰ç¼–ç å™¨
   - Patch embedding
   - 32å±‚ transformer blocks
   - ç©ºé—´æ³¨æ„åŠ›å’Œå…¨æ³¨æ„åŠ›å—
   - è¾“å‡ºæŠ•å½±åˆ°è¯­è¨€æ¨¡å‹ç»´åº¦

4. **Qwen25VLInferencePipeline**: æ¨ç†ç®¡é“
   - æ¨¡å‹åŠ è½½å’Œæƒé‡æ˜ å°„
   - å›¾ç‰‡é¢„å¤„ç†
   - å¤šæ¨¡æ€è¾“å…¥æ„å»º
   - ç”Ÿæˆå’Œé‡‡æ ·é€»è¾‘
```

## å®‰è£…ä¾èµ–

### 1. mlx-swift åŒ…

åœ¨ Xcode ä¸­æ·»åŠ åŒ…ä¾èµ–ï¼š
```
https://github.com/ml-explore/mlx-swift.git
```

æˆ–åœ¨ `Package.swift` ä¸­æ·»åŠ ï¼š
```swift
dependencies: [
    .package(url: "https://github.com/ml-explore/mlx-swift.git", from: "0.10.0")
]
```

### 2. æ¨¡å‹æ–‡ä»¶

ç¡®ä¿æœ¬åœ° `Models` ç›®å½•ä¸‹åŒ…å« Qwen2.5-VL-3B æ¨¡å‹æ–‡ä»¶ã€‚

## ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ç”¨æ³•

```swift
import QwenVLSwift

// ç®€å•çš„ç¾å­¦åˆ†æ
do {
    let result = try aestheticAnalysis(imagePath: "demo.png")
    print(result)
} catch {
    print("åˆ†æå¤±è´¥: \(error)")
}
```

### é«˜çº§ç”¨æ³•

```swift
// åˆ›å»ºæ¨ç†å®ä¾‹
let inference = QwenVLInference(
    modelPath: "./Models/models--mlx-community--Qwen2.5-VL-3B-Instruct-4bit/snapshots/46d4cf06a06ffc1a766c214174f9cbed2f45bcab",
    maxTokens: 512,
    temperature: 0.0
)

// åŒæ­¥åˆ†æ
do {
    let result = try inference.generateAestheticAnalysis(
        imagePath: "demo.png",
        prompt: "è¯·åˆ†æè¿™å¼ å›¾ç‰‡çš„ç¾å­¦ç‰¹ç‚¹",
        maxSize: 1024
    )
    print(result)
} catch {
    print("åˆ†æå¤±è´¥: \(error)")
}
```

### æµå¼è¾“å‡º

```swift
// æµå¼åˆ†æ
inference.generateAestheticAnalysisStream(
    imagePath: "demo.png",
    prompt: "è¯·åˆ†æè¿™å¼ å›¾ç‰‡çš„ç¾å­¦ç‰¹ç‚¹"
) { result in
    switch result {
    case .success(let chunk):
        print(chunk, terminator: "")
    case .failure(let error):
        print("é”™è¯¯: \(error)")
    }
}
```

## iOS é›†æˆç¤ºä¾‹

```swift
import UIKit
import QwenVLSwift

class ViewController: UIViewController {
    @IBOutlet weak var imageView: UIImageView!
    @IBOutlet weak var analysisTextView: UITextView!
    
    let inference = QwenVLInference()
    
    @IBAction func analyzeImage(_ sender: UIButton) {
        guard let image = imageView.image else { return }
        
        // ä¿å­˜å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶
        let tempURL = saveImageToTemp(image)
        
        // å¼€å§‹åˆ†æ
        analysisTextView.text = "æ­£åœ¨åˆ†æ..."
        
        inference.generateAestheticAnalysisStream(
            imagePath: tempURL.path,
            prompt: "è¯·åˆ†æè¿™å¼ ç…§ç‰‡çš„ç¾å­¦ç‰¹ç‚¹",
            maxSize: 512  // iOS ä¸Šä½¿ç”¨è¾ƒå°å°ºå¯¸ä»¥èŠ‚çœå†…å­˜
        ) { [weak self] result in
            DispatchQueue.main.async {
                switch result {
                case .success(let chunk):
                    self?.analysisTextView.text += chunk
                case .failure(let error):
                    self?.analysisTextView.text = "åˆ†æå¤±è´¥: \(error.localizedDescription)"
                }
            }
        }
    }
    
    private func saveImageToTemp(_ image: UIImage) -> URL {
        let tempDir = FileManager.default.temporaryDirectory
        let tempURL = tempDir.appendingPathComponent(UUID().uuidString + ".png")
        
        if let data = image.pngData() {
            try? data.write(to: tempURL)
        }
        
        return tempURL
    }
}
```

## ç¼–è¯‘å’Œè¿è¡Œ

### å‘½ä»¤è¡Œç¼–è¯‘

```bash
# ç¼–è¯‘
xcodebuild build -scheme QwenVLSwift-Package -destination 'platform=OS X'

# è¿è¡Œç¤ºä¾‹
xcodebuild build -scheme QwenVLExample -destination 'platform=OS X'
./QwenVLExample
```

### Xcode ç¼–è¯‘

1. æ‰“å¼€ Xcode
2. é€‰æ‹© "File" â†’ "Open" â†’ é€‰æ‹©é¡¹ç›®ç›®å½•
3. é€‰æ‹©ç›®æ ‡å¹³å°ï¼ˆiOS/macOSï¼‰
4. ç‚¹å‡» "Build" æŒ‰é’®

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å†…å­˜ä½¿ç”¨

- åœ¨ iOS è®¾å¤‡ä¸Šï¼Œå»ºè®®è®¾ç½® `maxSize` å‚æ•°ä¸º 512 æˆ–æ›´å°
- åŠæ—¶è°ƒç”¨ `clearMemory()` æ–¹æ³•æ¸…ç†å†…å­˜
- å¤„ç†å¤§é‡å›¾ç‰‡æ—¶ï¼Œè€ƒè™‘æ‰¹é‡å¤„ç†ä»¥é¿å…å†…å­˜å³°å€¼

### æ¨ç†é€Ÿåº¦

- ä½¿ç”¨è¾ƒå°çš„ `maxTokens` å€¼å¯ä»¥å‡å°‘æ¨ç†æ—¶é—´
- è®¾ç½®åˆé€‚çš„ `temperature` å€¼å¹³è¡¡ç”Ÿæˆè´¨é‡å’Œé€Ÿåº¦
- é¢„å…ˆåŠ è½½æ¨¡å‹ä»¥é¿å…é‡å¤åŠ è½½å¼€é”€

## é”™è¯¯å¤„ç†

```swift
do {
    let result = try aestheticAnalysis(imagePath: "demo.png")
    print(result)
} catch QwenVLError.modelLoadFailed(let message) {
    print("æ¨¡å‹åŠ è½½å¤±è´¥: \(message)")
} catch QwenVLError.imageProcessingFailed(let message) {
    print("å›¾ç‰‡å¤„ç†å¤±è´¥: \(message)")
} catch QwenVLError.inferenceError(let message) {
    print("æ¨ç†é”™è¯¯: \(message)")
} catch {
    print("æœªçŸ¥é”™è¯¯: \(error)")
}
```

## æ”¯æŒçš„å›¾ç‰‡æ ¼å¼

- PNG (.png)
- JPEG (.jpg, .jpeg)
- HEIC (.heic, .heif)
- WebP (.webp)
- BMP (.bmp)
- TIFF (.tiff, .tif)
- GIF (.gif)

## æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹ä¾èµ–**: éœ€è¦æœ¬åœ°éƒ¨ç½² Qwen2.5-VL-3B æ¨¡å‹
2. **å†…å­˜éœ€æ±‚**: æ¨ç†è¿‡ç¨‹éœ€è¦è¶³å¤Ÿçš„ GPU å†…å­˜
3. **å¹³å°é™åˆ¶**: ç›®å‰ä»…æ”¯æŒ Apple Silicon è®¾å¤‡
4. **ç½‘ç»œ**: å®Œå…¨ç¦»çº¿è¿è¡Œï¼Œæ— éœ€ç½‘ç»œè¿æ¥

## æ•…éšœæ’é™¤

### æ¨¡å‹åŠ è½½å¤±è´¥
- æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®è®¤æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
- éªŒè¯ safetensors æ–‡ä»¶æ˜¯å¦å­˜åœ¨

### å†…å­˜ä¸è¶³
- å‡å° `maxSize` å‚æ•°
- é™ä½ `maxTokens` å€¼
- è°ƒç”¨ `clearMemory()` æ¸…ç†ç¼“å­˜

### å›¾ç‰‡å¤„ç†å¤±è´¥
- æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
- ç¡®è®¤å›¾ç‰‡æ ¼å¼æ˜¯å¦æ”¯æŒ
- éªŒè¯å›¾ç‰‡æ–‡ä»¶æ˜¯å¦æŸå

## è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªä¸åŸå§‹ mlx-swift ç›¸åŒçš„è®¸å¯è¯æ¡æ¬¾ã€‚

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªå®ç°ã€‚