#!/usr/bin/env python3
"""
Qwen2.5-VL-3B ç»Ÿä¸€æ¨ç†è„šæœ¬
å°†æ‰€æœ‰åŠŸèƒ½åˆå¹¶åˆ°å•ä¸ªæ–‡ä»¶ä¸­ï¼Œæä¾›æµå¼è¾“å‡ºçš„å›¾åƒç¾å­¦åˆ†æ
åŸºäº MLX æ¡†æ¶çš„æœ¬åœ°æ¨ç†å®ç°
"""

import os
import sys
import json
import re
import logging
import argparse
from typing import Optional, Dict, Any, List, Tuple, Generator
from pathlib import Path
from dataclasses import dataclass
from PIL import Image
import mlx.core as mx
import mlx.nn as nn
import numpy as np
import datetime


# ============================================================================
# æ•°æ®ç±»å®šä¹‰
# ============================================================================

@dataclass
class AestheticScore:
    """ç¾å­¦è¯„åˆ†æ•°æ®ç±»"""
    composition: float  # æ„å›¾
    focal_length: float  # ç„¦æ®µ
    contrast_exposure_brightness: float  # å¯¹æ¯”åº¦&æ›å…‰åº¦&äº®åº¦
    overall: float  # ç»¼åˆè¯„åˆ†
    
    def to_dict(self) -> Dict:
        return {
            "composition": self.composition,
            "focal_length": self.focal_length, 
            "contrast_exposure_brightness": self.contrast_exposure_brightness,
            "overall": self.overall
        }


@dataclass 
class AestheticAnalysis:
    """ç¾å­¦åˆ†æç»“æœæ•°æ®ç±»"""
    composition_analysis: str
    focal_length_analysis: str
    contrast_exposure_brightness_analysis: str
    overall_evaluation: str
    suggestions: str
    scores: AestheticScore
    
    def to_dict(self) -> Dict:
        return {
            "composition_analysis": self.composition_analysis,
            "focal_length_analysis": self.focal_length_analysis,
            "contrast_exposure_brightness_analysis": self.contrast_exposure_brightness_analysis,
            "overall_evaluation": self.overall_evaluation,
            "suggestions": self.suggestions,
            "scores": self.scores.to_dict()
        }


# ============================================================================
# ç¾å­¦åˆ†æå™¨
# ============================================================================

class AestheticAnalyzer:
    """å›¾åƒç¾å­¦åˆ†æå™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        
    def parse_response(self, response: str) -> AestheticAnalysis:
        """
        è§£ææ¨¡å‹å“åº”ï¼Œæå–ç»“æ„åŒ–çš„ç¾å­¦åˆ†æç»“æœ
        
        Args:
            response: æ¨¡å‹ç”Ÿæˆçš„å“åº”æ–‡æœ¬
            
        Returns:
            ç»“æ„åŒ–çš„ç¾å­¦åˆ†æç»“æœ
        """
        try:
            # åˆå§‹åŒ–é»˜è®¤å€¼
            composition_analysis = ""
            focal_length_analysis = ""
            contrast_exposure_brightness_analysis = ""
            overall_evaluation = ""
            suggestions = ""
            
            # é»˜è®¤è¯„åˆ†
            composition_score = 0.0
            focal_length_score = 0.0
            contrast_exposure_brightness_score = 0.0
            overall_score = 0.0
            
            # åˆ†æç»´åº¦éƒ¨åˆ†
            dimension_pattern = r"ç»´åº¦åˆ†æä¸è¯„åˆ†ï¼š(.*?)ç»¼åˆè¯„åˆ†ï¼š"
            dimension_match = re.search(dimension_pattern, response, re.DOTALL)
            
            if dimension_match:
                dimension_content = dimension_match.group(1)
                
                # æå–æ„å›¾åˆ†æ
                composition_pattern = r"æ„å›¾ï¼š(.*?)(?=ç„¦æ®µï¼š|å¯¹æ¯”åº¦|$)"
                composition_match = re.search(composition_pattern, dimension_content, re.DOTALL)
                if composition_match:
                    composition_text = composition_match.group(1).strip()
                    composition_analysis = self._clean_text(composition_text)
                    composition_score = self._extract_score(composition_text)
                
                # æå–ç„¦æ®µåˆ†æ
                focal_pattern = r"ç„¦æ®µï¼š(.*?)(?=å¯¹æ¯”åº¦|$)"
                focal_match = re.search(focal_pattern, dimension_content, re.DOTALL)
                if focal_match:
                    focal_text = focal_match.group(1).strip()
                    focal_length_analysis = self._clean_text(focal_text)
                    focal_length_score = self._extract_score(focal_text)
                
                # æå–å¯¹æ¯”åº¦&æ›å…‰åº¦&äº®åº¦åˆ†æ
                contrast_pattern = r"å¯¹æ¯”åº¦&æ›å…‰åº¦&äº®åº¦ï¼š(.*?)(?=$|\n\n)"
                contrast_match = re.search(contrast_pattern, dimension_content, re.DOTALL)
                if contrast_match:
                    contrast_text = contrast_match.group(1).strip()
                    contrast_exposure_brightness_analysis = self._clean_text(contrast_text)
                    contrast_exposure_brightness_score = self._extract_score(contrast_text)
            
            # æå–ç»¼åˆè¯„åˆ†
            overall_score_pattern = r"ç»¼åˆè¯„åˆ†ï¼š.*?(\d+\.?\d*)"
            overall_score_match = re.search(overall_score_pattern, response)
            if overall_score_match:
                overall_score = float(overall_score_match.group(1))
            
            # æå–ç»¼åˆè¯„ä»·ä¸å»ºè®®
            evaluation_pattern = r"ç»¼åˆè¯„ä»·ä¸å»ºè®®ï¼š(.*?)(?=$|\n\n\n)"
            evaluation_match = re.search(evaluation_pattern, response, re.DOTALL)
            if evaluation_match:
                evaluation_text = evaluation_match.group(1).strip()
                
                # åˆ†ç¦»è¯„ä»·å’Œå»ºè®®
                if "å»ºè®®" in evaluation_text:
                    parts = evaluation_text.split("å»ºè®®", 1)
                    overall_evaluation = parts[0].strip()
                    suggestions = "å»ºè®®" + parts[1].strip()
                else:
                    overall_evaluation = evaluation_text
            
            # åˆ›å»ºè¯„åˆ†å¯¹è±¡
            scores = AestheticScore(
                composition=composition_score,
                focal_length=focal_length_score,
                contrast_exposure_brightness=contrast_exposure_brightness_score,
                overall=overall_score
            )
            
            # åˆ›å»ºåˆ†æç»“æœå¯¹è±¡
            analysis = AestheticAnalysis(
                composition_analysis=composition_analysis,
                focal_length_analysis=focal_length_analysis,
                contrast_exposure_brightness_analysis=contrast_exposure_brightness_analysis,
                overall_evaluation=overall_evaluation,
                suggestions=suggestions,
                scores=scores
            )
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"è§£æå“åº”å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤åˆ†æç»“æœ
            return self._get_default_analysis()
    
    def _extract_score(self, text: str) -> float:
        """ä»æ–‡æœ¬ä¸­æå–è¯„åˆ†"""
        # æŸ¥æ‰¾è¯„åˆ†æ¨¡å¼ï¼šX.Xåˆ† æˆ– Xåˆ†
        score_pattern = r"(\d+\.?\d*)åˆ†"
        matches = re.findall(score_pattern, text)
        
        if matches:
            try:
                return float(matches[-1])  # å–æœ€åä¸€ä¸ªåŒ¹é…çš„åˆ†æ•°
            except ValueError:
                return 0.0
        
        return 0.0
    
    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ï¼Œç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦"""
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦å’Œæ¢è¡Œç¬¦
        cleaned = re.sub(r'\s+', ' ', text.strip())
        return cleaned
    
    def _get_default_analysis(self) -> AestheticAnalysis:
        """è·å–é»˜è®¤çš„åˆ†æç»“æœ"""
        default_scores = AestheticScore(
            composition=5.0,
            focal_length=5.0,
            contrast_exposure_brightness=5.0,
            overall=5.0
        )
        
        return AestheticAnalysis(
            composition_analysis="æ„å›¾åˆ†ææš‚ä¸å¯ç”¨",
            focal_length_analysis="ç„¦æ®µåˆ†ææš‚ä¸å¯ç”¨", 
            contrast_exposure_brightness_analysis="å¯¹æ¯”åº¦&æ›å…‰åº¦&äº®åº¦åˆ†ææš‚ä¸å¯ç”¨",
            overall_evaluation="æ•´ä½“è¯„ä»·æš‚ä¸å¯ç”¨",
            suggestions="å»ºè®®æš‚ä¸å¯ç”¨",
            scores=default_scores
        )


# ============================================================================
# Qwen2.5-VL æ¨ç†å¼•æ“
# ============================================================================

class QwenVLInference:
    """Qwen2.5-VL-3B æ¨¡å‹æ¨ç†ç±»"""
    
    def __init__(self, model_path: str, device: str = "gpu"):
        """
        åˆå§‹åŒ–æ¨ç†å¼•æ“
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            device: è¿è¡Œè®¾å¤‡ ('gpu' æˆ– 'cpu')
        """
        self.model_path = Path(model_path)
        self.device = device
        self.model = None
        self.tokenizer = None
        self.config = None
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
        # åŠ è½½æ¨¡å‹é…ç½®
        self._load_config()
        
        # åŠ è½½åˆ†è¯å™¨
        self._load_tokenizer()
        
        # åŠ è½½æ¨¡å‹
        self._load_model()
        
    def _load_config(self):
        """åŠ è½½æ¨¡å‹é…ç½®"""
        config_path = self.model_path / "config.json"
        if not config_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)
            
        self.logger.info(f"å·²åŠ è½½æ¨¡å‹é…ç½®: {self.config['model_type']}")
        
    def _load_tokenizer(self):
        """åŠ è½½åˆ†è¯å™¨"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„ MLX tokenizer å®ç°è¿›è¡Œè°ƒæ•´
        tokenizer_path = self.model_path / "tokenizer.json"
        if not tokenizer_path.exists():
            raise FileNotFoundError(f"åˆ†è¯å™¨æ–‡ä»¶ä¸å­˜åœ¨: {tokenizer_path}")
            
        self.logger.info("åˆ†è¯å™¨åŠ è½½å®Œæˆ")
        
    def _load_model(self):
        """åŠ è½½ MLX æ¨¡å‹"""
        try:
            # ä½¿ç”¨ MLX åŠ è½½é‡åŒ–æ¨¡å‹
            model_file = self.model_path / "model.safetensors"
            if not model_file.exists():
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_file}")
            
            # è®¾ç½® MLX è®¾å¤‡
            if self.device == "gpu" and mx.metal.is_available():
                mx.set_default_device(mx.gpu)
                self.logger.info("ä½¿ç”¨ GPU (Metal) è¿è¡Œæ¨ç†")
            else:
                mx.set_default_device(mx.cpu)
                self.logger.info("ä½¿ç”¨ CPU è¿è¡Œæ¨ç†")
                
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„æ¨¡å‹åŠ è½½é€»è¾‘
            # ç”±äº MLX çš„ Qwen2.5-VL æ”¯æŒå¯èƒ½éœ€è¦ç‰¹å®šçš„å®ç°
            self.logger.info("æ¨¡å‹åŠ è½½å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def preprocess_image(self, image_path: str) -> mx.array:
        """
        é¢„å¤„ç†å›¾åƒ
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            é¢„å¤„ç†åçš„å›¾åƒå¼ é‡
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
        try:
            # åŠ è½½å›¾åƒ
            image = Image.open(image_path).convert('RGB')
            
            # è·å–è§†è§‰é…ç½®
            vision_config = self.config.get('vision_config', {})
            patch_size = vision_config.get('patch_size', 14)
            
            # è°ƒæ•´å›¾åƒå°ºå¯¸ - é€šå¸¸éœ€è¦è°ƒæ•´åˆ°æ¨¡å‹æœŸæœ›çš„å°ºå¯¸
            # è¿™é‡Œä½¿ç”¨ 448x448 ä½œä¸ºç¤ºä¾‹ï¼Œå®é™…å¯èƒ½éœ€è¦æ ¹æ®æ¨¡å‹é…ç½®è°ƒæ•´
            target_size = (448, 448)
            image = image.resize(target_size, Image.Resampling.LANCZOS)
            
            # è½¬æ¢ä¸ºæ•°ç»„å¹¶æ ‡å‡†åŒ–
            image_array = np.array(image).astype(np.float32) / 255.0
            
            # æ ‡å‡†åŒ– (ImageNet æ ‡å‡†)
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            image_array = (image_array - mean) / std
            
            # è½¬æ¢ä¸º MLX æ•°ç»„å¹¶è°ƒæ•´ç»´åº¦ (H, W, C) -> (1, C, H, W)
            image_tensor = mx.array(image_array.transpose(2, 0, 1))
            image_tensor = mx.expand_dims(image_tensor, axis=0)
            
            self.logger.info(f"å›¾åƒé¢„å¤„ç†å®Œæˆï¼Œå°ºå¯¸: {image_tensor.shape}")
            return image_tensor
            
        except Exception as e:
            self.logger.error(f"å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}")
            raise
    
    def preprocess_text(self, prompt: str) -> mx.array:
        """
        é¢„å¤„ç†æ–‡æœ¬æç¤º
        
        Args:
            prompt: æ–‡æœ¬æç¤º
            
        Returns:
            ç¼–ç åçš„æ–‡æœ¬å¼ é‡
        """
        try:
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„æ–‡æœ¬ç¼–ç é€»è¾‘
            # ä½¿ç”¨ Qwen2.5 çš„ç‰¹æ®Š token
            vision_start_token = self.config.get('vision_start_token_id', 151652)
            vision_end_token = self.config.get('vision_end_token_id', 151653)
            
            # æ„å»ºå¸¦æœ‰è§†è§‰ token çš„æç¤º
            full_prompt = f"<|vision_start|><|image_pad|><|vision_end|>{prompt}"
            
            # è¿™é‡Œåº”è¯¥ä½¿ç”¨å®é™…çš„ tokenizer è¿›è¡Œç¼–ç 
            # ä½œä¸ºç¤ºä¾‹ï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªå ä½ç¬¦å¼ é‡
            # å®é™…å®ç°éœ€è¦é›†æˆçœŸæ­£çš„ tokenizer
            
            self.logger.info("æ–‡æœ¬é¢„å¤„ç†å®Œæˆ")
            return mx.array([1, 2, 3])  # å ä½ç¬¦
            
        except Exception as e:
            self.logger.error(f"æ–‡æœ¬é¢„å¤„ç†å¤±è´¥: {e}")
            raise
    
    def _mock_aesthetic_analysis_stream(self) -> Generator[str, None, None]:
        """
        æ¨¡æ‹Ÿæµå¼ç¾å­¦åˆ†æå“åº”
        å®é™…å®ç°ä¸­åº”è¯¥è°ƒç”¨çœŸæ­£çš„æ¨¡å‹è¿›è¡Œæµå¼ç”Ÿæˆ
        """
        response_parts = [
            "ç»´åº¦åˆ†æä¸è¯„åˆ†ï¼š\n",
            "- æ„å›¾ï¼šé‡‡ç”¨äº†è¾ƒä¸ºä¼ ç»Ÿçš„æµ·æ™¯æ„å›¾ï¼Œå‰æ™¯çš„å²©çŸ³å½¢æˆäº†å¤©ç„¶çš„å¼•å¯¼çº¿ï¼Œ",
            "å°†è§†çº¿å¼•å‘è¿œå¤„çš„æµ·å¹³é¢ã€‚ç”»é¢éµå¾ªäº†ä¸‰åˆ†æ³•åŸåˆ™ï¼Œ",
            "æµ·å¹³çº¿ä½äºç”»é¢ä¸‹ä¸‰åˆ†ä¹‹ä¸€å¤„ï¼Œæ„å›¾ç›¸å¯¹å¹³è¡¡ã€‚",
            "ä½†å²©çŸ³å æ®äº†è¿‡å¤šå‰æ™¯ç©ºé—´ï¼Œå¯èƒ½å‹æŠ‘äº†æµ·æ´‹çš„å¼€é˜”æ„Ÿã€‚è¯„åˆ†ï¼š7.2åˆ†\n",
            "- ç„¦æ®µï¼šä½¿ç”¨é€‚ä¸­ç„¦æ®µæ‹æ‘„ï¼Œé€è§†æ•ˆæœè‡ªç„¶ï¼Œæ²¡æœ‰æ˜æ˜¾çš„å˜å½¢ã€‚",
            "ç„¦æ®µé€‰æ‹©é€‚åˆè¡¨ç°æµ·å²¸é£å…‰çš„å±‚æ¬¡æ„Ÿï¼Œ",
            "èƒ½å¤Ÿè¾ƒå¥½åœ°å¹³è¡¡å‰æ™¯å²©çŸ³å’Œè¿œæ™¯æµ·é¢çš„å…³ç³»ã€‚è¯„åˆ†ï¼š7.8åˆ†\n",  
            "- å¯¹æ¯”åº¦&æ›å…‰åº¦&äº®åº¦ï¼šç”»é¢å¯¹æ¯”åº¦é€‚ä¸­ï¼Œ",
            "å¤©ç©ºçš„è“è‰²ä¸å²©çŸ³çš„æš–è‰²è°ƒå½¢æˆäº†è‰¯å¥½çš„è‰²å½©å¯¹æ¯”ã€‚",
            "æ›å…‰åŸºæœ¬å‡†ç¡®ï¼Œå¤©ç©ºå’Œæµ·æ°´çš„ç»†èŠ‚éƒ½æœ‰è¾ƒå¥½çš„ä¿ç•™ï¼Œ",
            "æ²¡æœ‰æ˜æ˜¾çš„è¿‡æ›æˆ–æ¬ æ›ç°è±¡ã€‚æ•´ä½“äº®åº¦é€‚å®œï¼Œ",
            "ç¬¦åˆæ—¥é—´æµ·æ™¯çš„è‡ªç„¶å…‰ç…§æ¡ä»¶ã€‚è¯„åˆ†ï¼š8.1åˆ†\n\n",
            "ç»¼åˆè¯„åˆ†ï¼š7.7ï¼ˆ1-10åˆ†ï¼‰\n\n",
            "ç»¼åˆè¯„ä»·ä¸å»ºè®®ï¼šè¿™æ˜¯ä¸€å¹…è¾ƒä¸ºæ ‡å‡†çš„æµ·å²¸é£å…‰æ‘„å½±ä½œå“ã€‚",
            "ä¼˜ç‚¹åŒ…æ‹¬è‰²å½©æ­é…å’Œè°ã€æ›å…‰æ§åˆ¶å¾—å½“ã€ç”»é¢å±‚æ¬¡æ¸…æ™°ã€‚",
            "å»ºè®®æ”¹è¿›ï¼š1ï¼‰å¯ä»¥å°è¯•ä¸åŒçš„æ‹æ‘„è§’åº¦ï¼Œ",
            "å‡å°‘å‰æ™¯å²©çŸ³çš„å æ¯”ï¼Œçªå‡ºæµ·æ´‹çš„å£®é˜”æ„Ÿï¼›",
            "2ï¼‰ç­‰å¾…æ›´ä½³çš„å…‰çº¿æ¡ä»¶ï¼Œå¦‚é»„é‡‘æ—¶æ®µçš„æ¸©æš–å…‰çº¿æˆ–è€…æˆå‰§æ€§çš„äº‘å±‚ï¼›",
            "3ï¼‰è€ƒè™‘ä½¿ç”¨æ¸å˜é•œå¹³è¡¡å¤©ç©ºå’Œåœ°é¢çš„å…‰æ¯”ï¼Œ",
            "è¿›ä¸€æ­¥æå‡ç”»é¢çš„è§†è§‰æ•ˆæœã€‚\n"
        ]
        
        import time
        for part in response_parts:
            yield part
            time.sleep(0.1)  # æ¨¡æ‹Ÿç”Ÿæˆå»¶è¿Ÿ
    
    def generate_response_stream(self, image_path: str, prompt: str, max_tokens: int = 2048) -> Generator[str, None, None]:
        """
        ç”Ÿæˆæµå¼å“åº”
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            prompt: æ–‡æœ¬æç¤º
            max_tokens: æœ€å¤§ç”Ÿæˆ token æ•°é‡
            
        Yields:
            ç”Ÿæˆçš„æ–‡æœ¬ç‰‡æ®µ
        """
        try:
            # é¢„å¤„ç†è¾“å…¥
            image_tensor = self.preprocess_image(image_path)
            text_tensor = self.preprocess_text(prompt)
            
            # æ‰§è¡Œæ¨ç†
            # è¿™é‡Œéœ€è¦å®ç°å®é™…çš„æ¨¡å‹æ¨ç†é€»è¾‘
            # ç”±äº MLX çš„ Qwen2.5-VL å®ç°å¯èƒ½æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªæ¡†æ¶
            
            self.logger.info("å¼€å§‹æµå¼æ¨ç†...")
            
            # ä½¿ç”¨æ¨¡æ‹Ÿçš„æµå¼å“åº” - å®é™…å®ç°éœ€è¦è°ƒç”¨æ¨¡å‹
            for chunk in self._mock_aesthetic_analysis_stream():
                yield chunk
            
            self.logger.info("æµå¼æ¨ç†å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"æµå¼æ¨ç†å¤±è´¥: {e}")
            yield f"æ¨ç†å¤±è´¥: {e}"


# ============================================================================
# ä¸»è¦æ¨ç†å‡½æ•°
# ============================================================================

def infer_with_qwen(prompt: str, image_path: str, model_path: str = "./Models", 
                   device: str = "gpu", stream: bool = True) -> Generator[str, None, None]:
    """
    ä½¿ç”¨ Qwen2.5-VL-3B è¿›è¡Œå›¾åƒç¾å­¦åˆ†ææ¨ç†çš„ä¸»å‡½æ•°
    
    Args:
        prompt: æ–‡å­—æç¤º
        image_path: å›¾ç‰‡è·¯å¾„
        model_path: æ¨¡å‹è·¯å¾„
        device: è¿è¡Œè®¾å¤‡ ('gpu' æˆ– 'cpu')
        stream: æ˜¯å¦æµå¼è¾“å‡º
        
    Yields:
        æµå¼è¾“å‡ºçš„ç…§ç‰‡è¯„ä»·æ–‡æœ¬
    """
    try:
        # æ£€æŸ¥è¾“å…¥
        if not os.path.exists(image_path):
            yield f"é”™è¯¯: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨ {image_path}"
            return
            
        if not os.path.exists(model_path):
            yield f"é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ {model_path}"
            return
        
        # åˆå§‹åŒ–æ¨ç†å¼•æ“
        inference_engine = QwenVLInference(model_path, device=device)
        
        # æ‰§è¡Œæµå¼æ¨ç†
        if stream:
            for chunk in inference_engine.generate_response_stream(image_path, prompt):
                yield chunk
        else:
            # éæµå¼æ¨¡å¼ï¼Œæ”¶é›†æ‰€æœ‰æ–‡æœ¬åä¸€æ¬¡æ€§è¿”å›
            full_response = ""
            for chunk in inference_engine.generate_response_stream(image_path, prompt):
                full_response += chunk
            yield full_response
            
    except Exception as e:
        yield f"æ¨ç†è¿‡ç¨‹å‡ºç°é”™è¯¯: {e}"


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================

def load_prompt_template(prompt_file: str) -> str:
    """åŠ è½½æç¤ºæ¨¡æ¿"""
    if not os.path.exists(prompt_file):
        raise FileNotFoundError(f"æç¤ºæ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
    
    with open(prompt_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æå– <prompt> æ ‡ç­¾ä¸­çš„å†…å®¹
    start_tag = "<prompt>"
    end_tag = "</prompt>"
    
    start_idx = content.find(start_tag)
    end_idx = content.find(end_tag)
    
    if start_idx == -1 or end_idx == -1:
        raise ValueError("æç¤ºæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œç¼ºå°‘ <prompt> æ ‡ç­¾")
    
    prompt = content[start_idx + len(start_tag):end_idx].strip()
    return prompt


def setup_logging(log_level: str = "INFO"):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    level = getattr(logging, log_level.upper(), logging.INFO)
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )


def get_image_files(path: str, extensions: List[str] = None) -> List[str]:
    """
    è·å–æŒ‡å®šè·¯å¾„ä¸‹çš„å›¾åƒæ–‡ä»¶
    
    Args:
        path: æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
        extensions: æ”¯æŒçš„å›¾åƒæ‰©å±•å
        
    Returns:
        å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    if extensions is None:
        extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']
    
    path_obj = Path(path)
    
    if path_obj.is_file():
        # å•ä¸ªæ–‡ä»¶
        if path_obj.suffix.lower() in extensions:
            return [str(path_obj)]
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: {path_obj.suffix}")
    
    elif path_obj.is_dir():
        # ç›®å½•
        image_files = []
        for ext in extensions:
            image_files.extend(path_obj.glob(f"**/*{ext}"))
            image_files.extend(path_obj.glob(f"**/*{ext.upper()}"))
        
        return [str(f) for f in sorted(image_files)]
    
    else:
        raise FileNotFoundError(f"è·¯å¾„ä¸å­˜åœ¨: {path}")


# ============================================================================
# ä¸»å‡½æ•°å’Œå‘½ä»¤è¡Œæ¥å£
# ============================================================================

def demo_stream_inference():
    """æ¼”ç¤ºæµå¼æ¨ç†åŠŸèƒ½"""
    print("=== Qwen2.5-VL-3B æµå¼ç¾å­¦åˆ†ææ¼”ç¤º ===\n")
    
    # é…ç½®è·¯å¾„
    current_dir = Path(__file__).parent
    model_path = str(current_dir / "Models")
    image_path = str(current_dir / "demo.png")
    prompt_file = str(current_dir / "qwen_vl_3b_prompt.txt")
    
    try:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not Path(model_path).exists():
            print(f"é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ {model_path}")
            return
            
        if not Path(image_path).exists():
            print(f"é”™è¯¯: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨ {image_path}")
            return
            
        if not Path(prompt_file).exists():
            print(f"é”™è¯¯: æç¤ºæ–‡ä»¶ä¸å­˜åœ¨ {prompt_file}")
            return
        
        # åŠ è½½æç¤ºæ¨¡æ¿
        prompt_template = load_prompt_template(prompt_file)
        
        print(f"åˆ†æå›¾åƒ: {Path(image_path).name}")
        print(f"ä½¿ç”¨æ¨¡å‹: {model_path}")
        print("\nå¼€å§‹æµå¼åˆ†æ...\n")
        print("-" * 60)
        
        # æ‰§è¡Œæµå¼æ¨ç†
        for chunk in infer_with_qwen(prompt_template, image_path, model_path):
            print(chunk, end='', flush=True)
        
        print("\n" + "-" * 60)
        print("\nâœ… æµå¼åˆ†æå®Œæˆ!")
        
        # ä¿å­˜ç»“æœ
        output_file = current_dir / "aesthetic_analysis_result.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("å›¾åƒç¾å­¦åˆ†æç»“æœ\n")
            f.write("="*50 + "\n")
            f.write(f"å›¾åƒæ–‡ä»¶: {image_path}\n")
            f.write(f"åˆ†ææ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("\nåˆ†æç»“æœ:\n")
            
            # é‡æ–°è¿è¡Œæ¨ç†è·å–å®Œæ•´ç»“æœä¿å­˜
            full_result = ""
            for chunk in infer_with_qwen(prompt_template, image_path, model_path, stream=False):
                full_result += chunk
            f.write(full_result)
        
        print(f"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        print(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description="Qwen2.5-VL-3B ç»Ÿä¸€å›¾åƒç¾å­¦åˆ†æå·¥å…·")
    parser.add_argument("--demo", action="store_true", help="è¿è¡Œæ¼”ç¤ºæ¨¡å¼")
    parser.add_argument("--image", help="å›¾åƒæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--prompt", help="è‡ªå®šä¹‰æç¤ºæ–‡æœ¬")
    parser.add_argument("--prompt-file", help="æç¤ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model-path", default="./Models", help="æ¨¡å‹è·¯å¾„")
    parser.add_argument("--device", choices=['gpu', 'cpu'], default='gpu', help="è¿è¡Œè®¾å¤‡")
    parser.add_argument("--no-stream", action="store_true", help="ç¦ç”¨æµå¼è¾“å‡º")
    parser.add_argument("--log-level", choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], 
                       default='INFO', help="æ—¥å¿—çº§åˆ«")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.log_level)
    
    if args.demo:
        demo_stream_inference()
        return 0
    
    # æ£€æŸ¥å¿…è¦å‚æ•°
    if not args.image:
        print("é”™è¯¯: è¯·æŒ‡å®šå›¾åƒæ–‡ä»¶è·¯å¾„ (--image)")
        return 1
    
    # ç¡®å®šæç¤ºå†…å®¹
    if args.prompt:
        prompt = args.prompt
    elif args.prompt_file:
        try:
            prompt = load_prompt_template(args.prompt_file)
        except Exception as e:
            print(f"é”™è¯¯: åŠ è½½æç¤ºæ–‡ä»¶å¤±è´¥ - {e}")
            return 1
    else:
        # ä½¿ç”¨é»˜è®¤æç¤º
        prompt = "è¯·å¯¹è¿™å¼ å›¾ç‰‡è¿›è¡Œè¯¦ç»†çš„ç¾å­¦åˆ†æï¼ŒåŒ…æ‹¬æ„å›¾ã€ç„¦æ®µã€å¯¹æ¯”åº¦&æ›å…‰åº¦&äº®åº¦ç­‰æ–¹é¢ï¼Œå¹¶ç»™å‡ºè¯„åˆ†å’Œæ”¹è¿›å»ºè®®ã€‚"
    
    try:
        print(f"åˆ†æå›¾åƒ: {args.image}")
        print(f"ä½¿ç”¨è®¾å¤‡: {args.device}")
        print("\nå¼€å§‹åˆ†æ...\n")
        
        stream_mode = not args.no_stream
        for chunk in infer_with_qwen(prompt, args.image, args.model_path, args.device, stream_mode):
            print(chunk, end='', flush=True)
        
        print("\n\nâœ… åˆ†æå®Œæˆ!")
        return 0
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        return 1
    except Exception as e:
        print(f"\né”™è¯¯: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())